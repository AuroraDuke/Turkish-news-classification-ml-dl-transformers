{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c617721-2283-4c70-a8ca-de87c4a38a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2773d14-ae30-4a30-a438-ee035a314114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ilker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ilker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ilker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ilker\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # regular expression libary.\n",
    "import nltk # Natural Language toolkit\n",
    "nltk.download(\"stopwords\")  #downloading stopwords\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "nltk.download('wordnet')\n",
    "import nltk as nlp\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fdf878-9f3e-4831-90a2-9aba63e89f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "current_dir = os.getcwd()\n",
    "# Move up one level in the directory tree\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa3d6c3-8eb2-489e-9c99-462addd4432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the target file in the parent directory\n",
    "file_path = os.path.join(parent_dir, '7allV03.csv')\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "df_main = pd.read_csv(file_path, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539f866b-cd81-4aa1-ad05-c641f0e1e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>dunya</td>\n",
       "      <td>gizli belgeleri gözardı etmeyeceğiz suriye mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>ekonomi</td>\n",
       "      <td>700 milyon euro hortumlayan banker yakalandı ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>saglik</td>\n",
       "      <td>hamileyken diş tedavisi yapılır mı diş hekimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>kultur</td>\n",
       "      <td>nutuk özgün dilinde yayımlandı aramızdan ayrı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>spor</td>\n",
       "      <td>birbirimizi kırdırma operasyonu taner_aşkın ı...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>akp nin son sözü yarı başkanlık başkanlık sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>spor</td>\n",
       "      <td>amrabat tan ilginç benzetme ! galatasaray ın ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>teknoloji</td>\n",
       "      <td>samsung_galaxy_note 8 tablet tanıtıldı ! ve n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>dunya</td>\n",
       "      <td>bağımsızlığının 21 yılını kutladı ukrayna nın...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>saglik</td>\n",
       "      <td>burun spreylerindeki tehlike ! uzun süre buru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "1387      dunya    gizli belgeleri gözardı etmeyeceğiz suriye mu...\n",
       "2014    ekonomi    700 milyon euro hortumlayan banker yakalandı ...\n",
       "3357     saglik    hamileyken diş tedavisi yapılır mı diş hekimi...\n",
       "2111     kultur    nutuk özgün dilinde yayımlandı aramızdan ayrı...\n",
       "4046       spor    birbirimizi kırdırma operasyonu taner_aşkın ı...\n",
       "400     siyaset    akp nin son sözü yarı başkanlık başkanlık sis...\n",
       "3583       spor    amrabat tan ilginç benzetme ! galatasaray ın ...\n",
       "4356  teknoloji    samsung_galaxy_note 8 tablet tanıtıldı ! ve n...\n",
       "1385      dunya    bağımsızlığının 21 yılını kutladı ukrayna nın...\n",
       "2945     saglik    burun spreylerindeki tehlike ! uzun süre buru..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaee7af9-5f14-4de1-864b-2259de9c3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the existing KeyedVectors model\n",
    "model_path = os.path.join(current_dir, \"turkishword2vec\", \"trmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e031ff65-0492-46ba-9a40-1d9d0cf55bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc453502-2564-4d47-9c03-55bdae78eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kraliçe', 0.508816123008728), ('kralı', 0.47180891036987305), ('kralın', 0.4451238512992859), ('kraliçesi', 0.4190150201320648), ('prenses', 0.40713056921958923), ('hükümdar', 0.40560296177864075), ('prens', 0.3978962004184723), ('kraliçenin', 0.39632880687713623), ('veliaht', 0.38219931721687317), ('tahtı', 0.3773398995399475)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=[\"kral\", \"kadın\"], negative=[\"erkek\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a18b21c-5d32-4165-a0e9-1b1a3a2749ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert KeyedVectors to a trainable Word2Vec format\n",
    "word2vec_model = Word2Vec(vector_size=word_vectors.vector_size, min_count=1)\n",
    "word2vec_model.build_vocab([list(word_vectors.index_to_key)])  \n",
    "word2vec_model.wv.vectors = word_vectors.vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5342db2d-7d7b-414c-b64c-4c381e2cd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list=[]\n",
    "\n",
    "for text in df_main.text:\n",
    "    text = text.lower()  #Büyük harften -Küçük harfe çevirme\n",
    "    text = re.sub(\"[^abcçdefgğhıijklmnoöprsştuüvyz]\",\" \",text)\n",
    "    text=nltk.word_tokenize(text) # splits the words that are in the sentence from each other.\n",
    "    text =[word for word in text if not word in set(stopwords.words(\"turkish\"))]\n",
    "    lemma=nlp.WordNetLemmatizer()\n",
    "    text=[lemma.lemmatize(word) for word in text] # this code finds the root of the word for a word in the sentence and change them to their root form.  \n",
    "    text=\" \".join(text)\n",
    "    text_list.append(text) # store sentences in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8798799d-e782-4db4-aab8-0506d7312325",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for text in text_list:\n",
    "    text=nltk.word_tokenize(text)\n",
    "    tokens.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bcca06-fd6f-437c-a9f0-12b73c003ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 4900\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c8b6e9-44f1-42b9-801c-f743e9ac7659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anayasa', 'süreci', 'heba', 'edilmemeli', 'meclis', 'başkanı', 'cemil', 'çiçek', 'yeni', 'anayasa', 'çalışmalarıyla', 'ilgili', 'görüş', 'alışverişinde', 'bulunmak', 'üzere', 'parti', 'liderlerinden', 'randevu', 'istedi', 'erdoğan', 'la', 'yaptığı', 'görüşmenin', 'ardından', 'ntv', 'ye', 'konuşan', 'çiçek', 'umutsuz', 'değilim', 'süreç', 'heba', 'edilmemeli', 'dedi', 'meclis', 'başkanı', 'cemil', 'çiçek', 'yeni', 'anayasa', 'çalışmalarıyla', 'ilgili', 'parti', 'liderlerinden', 'randevu', 'istedi', 'çiçek', 'ilk', 'olarak', 'akşam', 'saatlerinde', 'ak', 'parti', 'genel', 'başkanı', 'başbakan', 'recep', 'tayyip', 'erdoğan', 'bir', 'araya', 'geldi', 'görüşmenin', 'ardından', 'ntv', 'ye', 'konuşan', 'çiçek', 'anayasa', 'çalışmalarıyla', 'ilgili', 'süreci', 'değerlendirdi', 'siyaset', 'umutsuzluk', 'üzerine', 'sürdürülemez', 'diyen', 'çiçek', 'realiteler', 'üzerine', 'görüşülmesi', 'gerektiğini', 'vurguladı', 'çiçek', 'anayasa', 'değişikliğine', 'dair', 'hiçbir', 'zaman', 'umutsuz', 'olmadığını', 'söyledi', 'bugüne', 'kadarki', 'süreç', 'heba', 'edilmemeli', 'ben', 'kendi', 'üzerime', 'düşeni', 'yapıyorum', 'konuştu', 'meclis', 'başkanı', 'liderlerle', 'görüşmesinin', 'ardından', 'muhtemelen', 'ocak', 'çarşamba', 'günü', 'komisyonu', 'toplayabileceğini', 'düşüncelerini', 'toplantıda', 'değerlendireceklerini', 'söyledi', 'yarın', 'saat', 'mhp', 'lideri', 'devlet', 'bahçeli', 'biraraya', 'gelecek', 'olan', 'çiçek', 'chp', 'lideri', 'kemal', 'kılıçdaroğlu', 'bdp', 'genel', 'başkanı', 'selahattin', 'demirtaş', 'tan', 'randevu', 'istedi', 'ntv']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2f44e6-ba38-4ffe-b149-66421ba9a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1152681\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total tokens\n",
    "tokens_per_sentence = [len(sentence) for sentence in tokens]  # Tokens per sentence\n",
    "total_tokens = sum(tokens_per_sentence)\n",
    "\n",
    "# Display the total and average tokens\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bbdb0e0-3f53-4cc1-9e03-bad2e7279648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657388, 5763405)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Update the vocabulary with new training data and fine-tune the model\n",
    "word2vec_model.build_vocab(tokens, update=True)\n",
    "word2vec_model.train(tokens, total_examples=len(tokens), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f214f9b-ead8-4bbc-903d-09b08533cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert the fine-tuned model back to KeyedVectors format\n",
    "fine_tuned_word_vectors = word2vec_model.wv  # Sadece kelime vektörleri alınır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "138a43cf-c117-4d06-b621-a14253838c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune edilmiş modelin ilişkileri:\n",
      "[('imkani', 0.6879574656486511), ('ashington', 0.6844908595085144), ('inci', 0.6756271719932556), ('eurogroup', 0.6755569577217102), ('sabancı', 0.6748382449150085), ('pakistan', 0.673166036605835), ('ırig', 0.6711039543151855), ('yunanistan', 0.6623532772064209), ('anicca', 0.6614623069763184), ('te', 0.6609153151512146)]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Test the fine-tuned model\n",
    "print(\"Fine-tune edilmiş modelin ilişkileri:\")\n",
    "print(fine_tuned_word_vectors.most_similar(positive=[\"kral\", \"kadın\"], negative=[\"erkek\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce18c1e8-f339-468f-9d8e-1951c98dcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Save the fine-tuned word vectors\n",
    "output_path = 'trmodel_finetune.kv'\n",
    "fine_tuned_word_vectors.save_word2vec_format(output_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f84c41-3d55-454c-b05c-9e903f6e0b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
